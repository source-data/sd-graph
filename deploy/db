#!/bin/bash
if [ -f .env ]
then
  echo "# loading .env file"
  export $(cat .env | sed 's/#.*//g' | xargs)
else
  echo "# .env file missing. Aborting"
  exit 1
fi
# echo "# starting docker"
# docker-compose  build
# docker-compose up -d

# echo "# defining indices"
# cat sdg/SD-indices.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

# echo "# import source data public data. Logging to `log/sdg.sdneo-publicsearch.log`"
# docker-compose run --rm flask python -m sdg.sdneo PUBLICSEARCH --api sdapi

# echo "# updating meca archives"
# aws s3 sync --request-payer requester --exclude "*" --include "*.meca" s3://biorxiv-src-monthly/Current_Content /usb01/shared/biorxiv-src-monthly
# # alternative using docker
# # docker run --rm -it -v ~/.aws:/root/.aws --mount type=bind,source=/raid/lemberge/sd-graph/biorxiv/Current_Content/July_2020,target=/root/Current_Content/July_2020 amazon/aws-cli s3 sync --request-payer requester --exclude "*" --include "*.meca" s3://biorxiv-src-monthly/Current_Content/July_2020 ./Current_Content/July_2020 --dryrun


# echo "# remove prelim articles obtained from the CrossRef and bioRxiv APIs"
# cat neotools/purge_prelim.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

# echo "# import full text biorxiv preprints"
# docker-compose run --rm -v /usb01/shared/biorxiv-src-monthly:/biorxiv-src-monthly flask python -m neotools.rxiv2neo /biorxiv-src-monthly --type meca

# echo "# import peer reviews from hypothesis"
# docker-compose run --rm flask python -m peerreview.neohypo

# echo "# smarttag specified collection of preprints"
# docker-compose run --rm flask python -m sdg.sdneo covid19 --api eebapi

# echo "# generate merged graph"
# cat sdg/SD-processing.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

# echo "# precompute the graph used by front end"
# cat sdg/SD-precompute.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

# echo "# publishing on twitter"
# docker-compose run --rm flask python -m twitter.update --limit-date 2020-07-01 # --GO_LIVE to go live with Twitter updates



dump_local_neo4j(){
  local DUMP_NAME=$1
  echo "[dumping neo4j] - start"
  echo "  * stopping docker-compose"
  # Make sure you dont have your neo4j running:
  docker-compose down

  echo "  * removing older dumps"
  docker run --rm --name neo4j-dump --env-file .env --mount type=bind,source=$PWD/data/neo4j-data,target=/data -it neo4j:3.5 find /data -type f -name graph.db.dump* -delete

  echo "  * dumping to data/neo4j-data/$DUMP_NAME"
  # dump the contents of your database using a temporary container
  docker run --rm --name neo4j-dump --env-file .env --mount type=bind,source=$PWD/data/neo4j-data,target=/data -it neo4j:3.5 bin/neo4j-admin dump --database=graph.db --to=data/$DUMP_NAME

  echo "  * restarting docker-compose"
  docker-compose up -d
  echo "[dumping neo4j] - done"
}

deploy_database_to_production(){
  local PRODUCTION_ADDRESS="ec2-user@eeb.sourcedata.io"
  local NEO4J_DUMP_LOCAL_PATH=$1
  deploy_database $PRODUCTION_ADDRESS $NEO4J_DUMP_LOCAL_PATH
}

deploy_database_to_staging(){
  local STAGING_ADDRESS="ec2-user@eeb-dev.sourcedata.io"
  local NEO4J_DUMP_LOCAL_PATH=$1
  deploy_database $STAGING_ADDRESS $NEO4J_DUMP_LOCAL_PATH
}

deploy_database(){
  local SERVER_ADDRESS=$1
  local NEO4J_DUMP_LOCAL_PATH=$2
  local NEO4J_DUMP_REMOTE_PATH="/home/ec2-user/sd-graph/graph.dump"
  echo "[deploy database] - $SERVER_ADDRESS"
  echo "  * scp dump $NEO4J_DUMP_LOCAL_PATH"
  scp $NEO4J_DUMP_LOCAL_PATH $SERVER_ADDRESS:NEO4J_DUMP_REMOTE_PATH

  echo "  * scp loading neo4j dump on remote"
  ssh $SERVER_ADDRESS "/bin/bash /home/ec2-user/deploy/__db__/remote"
}



NEO4J_DUMP_NAME="graph.db.dump.`date +%Y-%m-%d-%H.%M.%S`"
dump_local_neo4j $NEO4J_DUMP_NAME
# deploy_database_to_staging data/neo4j-data/$NEO4J_DUMP_NAME