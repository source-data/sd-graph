#!/bin/bash

# exit when any command fails
set -e
# enable !! command completion
# set -o history -o histexpand

describe_length() {
  local num="$1"
  local max="$2"
  if [ ${num} -gt ${max} ]; then
    echo "First ${max} of ${num}"
  else
    echo "All"
  fi
}

mail_developers(){
  local developers_emails="mainar@embl.de,lemberge@embl.de,eidens@embl.de"
  # local developers_emails="mainar@embl.de"
  local subject=$1
  local body_prefix=$2

  if [ ! -z $LOG_FILE ]; then
    local num_errors=$(grep -i error ${LOG_FILE} | wc -l)
    local max_errors=20
    local error_desc="$(describe_length ${num_errors} ${max_errors})"
    local errors_snippet="$(grep -i error ${LOG_FILE} | head -${max_errors})"

    local num_log_lines=$(cat ${LOG_FILE} | wc -l)
    local max_log_lines=100
    local log_desc="$(describe_length ${num_log_lines} ${max_log_lines})"
    local log_snippet=$(tail -${max_log_lines} "${LOG_FILE}")

    local body=$(cat <<END_HEREDOC
${body_prefix}

log file: ${LOG_FILE}

----------

${error_desc} error messages in the log:

${errors_snippet}

----------

${log_desc} lines from the log:

${log_snippet}
END_HEREDOC
)
  fi

  echo -e "$body" | mail -s "[sd-graph deploy/db] $subject" $developers_emails
}

on_exit(){
  local last_exit_code=$1
  local line_number=$last_line
  local last_cmd=$current_command
  if [ $last_exit_code -eq 0 ]; then
    mail_developers "$STAGE_NAME $PERIODICITY: success" "$last_cmd exited with code $last_exit_code"
  else
    mail_developers "$STAGE_NAME $PERIODICITY: errors" "$last_cmd exited with code $last_exit_code on line $line_number"
  fi
}

# https://medium.com/@dirk.avery/the-bash-trap-trap-ce6083f36700
# keep track of the last executed command
trap 'last_command=$current_command; current_command=$BASH_COMMAND; last_line=$LINENO' DEBUG
trap 'on_exit $?' EXIT


log(){
  local timestamp=$(date +%Y-%m-%d\ %H:%M:%S)
  echo "[deploy/db $STAGE_NAME $PERIODICITY $timestamp] $1"
}

load_dotenv(){
  if [ -f .env ]
  then
    log "loading .env file"
    export $(cat .env | sed 's/#.*//g' | xargs)
  else
    log ".env file missing. Aborting"
    exit 1
  fi
}


update_local_neo4j() {
  reset_indices() {
    # RUN THIS ONLY MANUALLY
    # remove indices from automatic steps
    log "defining indices"
    cat sdg/SD-indices.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD
  }

  update_open() {
    # always start with this when updating db
    log "opening the update"
    cat sdg/update_open.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD
  }

  update_fulltext_biorxiv() {
    # run monthly

    log "updating meca archives"
    aws s3 sync --request-payer requester --exclude "*" --include "*.meca" s3://biorxiv-src-monthly/Current_Content $BIORXIV_PATH #/mnt/usb01/shared/biorxiv-src-monthly

    log "remove prelim articles obtained from the CrossRef and bioRxiv APIs"
    cat neotools/purge_prelim.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "import full text biorxiv preprints"
    # this is missing the July_2020
    #docker-compose run --rm -v /usb01/shared/biorxiv-src-monthly:/biorxiv-src-monthly flask python -m neotools.rxiv2neo /biorxiv-src-monthly/July_2020 --type meca
    local PREVIOUS_MONTH=`LC_TIME=en_US.UTF-8 date --date='-1 month' +%B` # Biorxiv only publishes monthly updates when the month is over, meaning the 1st of September we get access to August content
    local YEAR=`date --date='-1 month' +%Y` # Biorxiv only publishes monthly updates when the month is over, meaning the 1st of September we get access to August content
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m neotools.rxiv2neo /app/biorxiv/"$PREVIOUS_MONTH"_"$YEAR" --type meca
  }

  import_peer_reviews() {
    # daily
    log "import peer reviews from peer-review databases & complete our db with biorxiv prelim api if our meca-fulltext-db missed one"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.neohypo hypothesis
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.neohypo rrc19
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.neohypo pci

    aws s3 sync s3://mecadoi-archives/batch/deposited "${MECADOI_PATH}"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.mecadoi --input-dir "/app/mecadoi" --no-dry-run
  }

  mark_peer_reviews_as_published() {
    # weekly
    log "updates publication status (find out if a preprint has been published in a journal)"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.published # maybe run only once a week?
  }

  smarttag() {
    # daily

    log "smarttag specified collection of preprints"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m sdg.sdneo subject-collections --api eebapi
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m sdg.sdneo refereed-preprints --api eebapi
  }

  import_SD() {
    # manually
    log "import source data public data. Logging to `log/sdg.sdneo-publicsearch.log`"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m sdg.sdneo PUBLICSEARCH --api sdapi
  }

  merge_and_precompute_graph() {
    # daily
    log "generate merged graph"
    cat sdg/SD-processing.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "neo4j graph data science"
    cat sdg/SD-gds.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "advanced graph data science"
    docker-compose -f docker-compose.deploy.yml run --rm flask python -m sdg.algonet

    log "build preprint peer review descriptor voc"
    cat sdg/build_preprint_review_descriptor_voc.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "review service descriptors"
    cat sdg/describe_review_services.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "precompute the graph used by front end"
    cat sdg/SD-precompute.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "precompute pilot docmap graph"
    cat sdg/SD-prepare-docmap.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

  }

  update_close() {
    # always run at the end of a db update
    log "closing the update"
    cat sdg/update_close.cql | docker-compose -f docker-compose.deploy.yml run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD
  }

  wait_for_neo4j() {
    log "Waiting for neo4j to become available..."
    docker-compose -f docker-compose.deploy.yml run --rm flask dockerize -wait tcp://neo4j:7687 -timeout 360s
    if [ $? -ne 0 ]; then
        log "neo4j probably failed to start, check the neo4j log for details. Aborting"
        exit 1
    fi
    log "neo4j is available"
  }


  log "starting docker"
  docker-compose -f docker-compose.deploy.yml build
  docker-compose -f docker-compose.deploy.yml up -d
  wait_for_neo4j


  local PERIODICITY=$1
  case $PERIODICITY in
    "monthly")
      log "Running monthly update"
      update_open # track update status
      update_fulltext_biorxiv # monthly
      import_peer_reviews # daily
      mark_peer_reviews_as_published # weekly
      smarttag # daily
      # import_SD # monthly
      merge_and_precompute_graph # daily
      update_close # track update status
      ;;
    "weekly")
      log "Running weekly update, it's Monday!"
      update_open # track update status
      import_peer_reviews # daily
      mark_peer_reviews_as_published # weekly
      smarttag # daily
      merge_and_precompute_graph # daily
      update_close # track update status
      ;;
    "daily")
      log "Running daily update"
      update_open # track update status
      import_peer_reviews # daily
      smarttag # daily
      merge_and_precompute_graph # daily
      update_close # track update status
      ;;
  esac

  log "done"
}



publish_on_twitter(){
  log "publishing on twitter"
  docker-compose -f docker-compose.deploy.yml run --rm flask python -m twitter.update --limit-date 2020-07-01 # --GO_LIVE to go live with Twitter updates
}


dump_local_neo4j(){
  local DUMP_NAME=$1
  log "[dumping neo4j] - start"
  log "  * stopping docker-compose"

  # Make sure you dont have your neo4j running:
  docker-compose -f docker-compose.deploy.yml down

  # rotate backup once before we dump, just in case some old files are still there
  rotate_backup

  log "  * setting right permissions to dir: dumps"
  sudo chown 7474:7474 dumps

  log "  * dumping to dumps/$DUMP_NAME"
  # dump the contents of your database using a temporary container
  docker run --rm --name neo4j-dump --env-file .env --mount type=bind,source=$PWD/data/neo4j-data,target=/data --mount type=bind,source=$PWD/dumps,target=/dumps neo4j:4.1 bin/neo4j-admin dump --database=neo4j --to=/dumps/$DUMP_NAME
  log "[dumping neo4j] - done"

  # log "  * restarting docker-compose"
  # docker-compose -f docker-compose.deploy.yml up -d

}

deploy_database(){
  local SERVER_ADDRESS="ec2-user@$1"
  local NEO4J_DUMP_LOCAL_PATH=$2
  local NEO4J_DUMP_REMOTE_PATH="/home/ec2-user/sd-graph/neo4j.dump"

  log "[deploy database] - $SERVER_ADDRESS"

  log "  * scp $NEO4J_DUMP_LOCAL_PATH"
  scp $NEO4J_DUMP_LOCAL_PATH $SERVER_ADDRESS:$NEO4J_DUMP_REMOTE_PATH

  log "  * scp loading neo4j dump on remote"
  ssh $SERVER_ADDRESS "cd /home/ec2-user/sd-graph && ./deploy/__db__/remote"

  local wait_for_docker_in_minutes=5
  log "  * waiting $wait_for_docker_in_minutes minutes to be sure docker is up and running"
  sleep $(( $wait_for_docker_in_minutes * 60 ))
}

rotate_backup(){
  # you may need to add something like this to your sudoers file
  #
  #     eeb ALL=(root) NOPASSWD: /bin/chown -R eeb\:eeb dumps
  #     eeb ALL=(root) NOPASSWD: /bin/chown 7474\:7474 dumps


  log "make sure all previously dumped databases files belong to our user"
  sudo /bin/chown -R `whoami`:`whoami` dumps

  log "  * rotating backups"
  logrotate deploy/__db__/logrotate-graph.db.dump.conf --state deploy/__db__/logrotate.state --force
}

cache_warmup(){
  local SERVER_ADDRESS="ec2-user@$1"
  ssh -tt $SERVER_ADDRESS "cd /home/ec2-user/sd-graph && ./deploy/cache_warmup --no-progress"
}

send_notifications(){
  log "sending notifications"

  # this file stores the time when the last notifications were sent. We need to send out notifications for all reviews posted after this point.
  file_last_notification="peerreview/last_notification.txt"
  date_format="--iso-8601=s"
  # if the file exists and has a valid date, use that. Otherwise use yesterday's date.
  after=$(date -f "${file_last_notification}" "${date_format}" || date --date "yesterday" "${date_format}")
  reviewed_by="review commons"
  recipient="${NOTIFICATIONS_RECIPIENT}"
  docker-compose -f docker-compose.deploy.yml run --rm flask python -m peerreview.notify --after "${after}" --reviewed-by "${reviewed_by}" --recipient "${recipient}" --no-dry-run
  # Update the time when the last notifications were sent to now.
  date "${date_format}" > "${file_last_notification}"
}

main() {

  # parse arguments
  while [ $# -gt 0 ]; do
    case "$1" in
      --stage_name*|-s*)
        if [[ "$1" != *=* ]]; then shift; fi # Value is next arg if no `=`
        STAGE_NAME="${1#*=}"
        ;;
      --periodicity*|-p*)
        if [[ "$1" != *=* ]]; then shift; fi
        PERIODICITY="${1#*=}"
        ;;
      --log_dir*|-L*)
        if [[ "$1" != *=* ]]; then shift; fi
        LOG_DIR="${1#*=}"
        ;;
      --help|-h)
        echo "--------------------------------------------------------------------------------------"
        echo "deploy db"
        echo "--------------------------------------------------------------------------------------"
        echo ""
        echo "deploy/db --stage_name STAGE_NAME --periodicity PERIODICITY [--log_dir 'PATH/TO/LOG/DIRECTORY']"
        echo ""
        echo "Options:"
        echo "  --help        | -h"
        echo "  --stage_name  | -s (staging|production)"
        echo "  --periodicity | -p (daily|weekly|monthly)"
        echo "  --log_dir    | -l 'quoted/path/to/log/directory'"
        echo ""
        echo "example of usage:"
        echo "  deploy/db --stage_name staging --periodicity daily --log_dir '/home/eeb/logs'"
        echo ""
        exit 0
        ;;
      *)
        >&2 printf "Error: Invalid argument\n"
        exit 1
        ;;
    esac
    shift
  done

  case $STAGE_NAME in
    "staging")
      REMOTE_HOST="eeb-dev.embo.org"
      ;;
    "production")
      REMOTE_HOST="eeb.embo.org"
      ;;
    *)
      echo "[ERROR] Argument - please specify a valid --stage_name (staging|production)"
      exit 1
      ;;
  esac

  case $PERIODICITY in
    "daily"|"weekly"|"monthly")
    # valid periodicity, continue
    ;;
    *)
    echo "[ERROR] Argument - please specify a valid --periodicity (daily|weekly|monthly)"
    exit 1
    ;;
  esac

  if [ -z $LOG_DIR ]; then
    LOG_DIR="."
  fi
  local timestamp="$(date +%Y-%m-%d_%H-%M-%S)"
  LOG_FILE="${LOG_DIR}/db-${STAGE_NAME}-${PERIODICITY}-${timestamp}.log"

  # LOG_FILE is specified, let's redirect stdout and stderr to the $LOG_FILE
  exec >> $LOG_FILE
  exec 2>&1

  log "############################################################"
  log "##"
  log "## STARTING SD-GRAPH DB DEPLOY"
  log "##"
  local

  # flock creates an exclusive lock on $LOCK_FILE. Everything within the round brackets is only executed if the lock
  # could be acquired; if the lock is already held by another process, flock returns instantly due to --nonblock.
  # This mechanism prevents any concurrent db updates for the same stage.
  LOCK_FILE="/var/lock/eeb-db-${STAGE_NAME}"
  (
    if ! flock --nonblock 9; then
      echo "Failed to acquire lock. Is another db update still running?"
      exit 1
    fi

    load_dotenv
    update_local_neo4j $PERIODICITY
    NEO4J_DUMP_NAME="neo4j.dump"
    dump_local_neo4j $NEO4J_DUMP_NAME
    deploy_database $REMOTE_HOST dumps/$NEO4J_DUMP_NAME
    rotate_backup
    cache_warmup $REMOTE_HOST
    send_notifications
  ) 9>${LOCK_FILE}

  log "##"
  log "## FINISHED SD-GRAPH DB DEPLOY"
  log "##"
  log "############################################################"
  echo "done :)"
}

main $@
