#!/bin/bash

# exit when any command fails
set -e
# enable !! command completion
# set -o history -o histexpand

mail_developers(){
  local developers_emails="mainar@embl.de,lemberge@embl.de"
  # local developers_emails="mainar@embl.de"
  local subject=$1
  local body=$2
  if [ ! -z $LOG_FILE ]; then
    local _log=`cat $LOG_FILE`
    local log="----------\n\nOutput of log file: $LOG_FILE\n$_log"
  fi
  echo -e "$2\n\n$log" | mail -s "[sd-graph deploy/db] $subject" $developers_emails
}

on_exit(){
  local last_exit_code=$1
  local line_number=$last_line
  local last_cmd=$current_command
  if [ $last_exit_code -eq 0 ]; then
    mail_developers "$STAGE_NAME $PERIODICITY: success" "$last_cmd exited with code $last_exit_code"
  else
    mail_developers "$STAGE_NAME $PERIODICITY: errors" "$last_cmd exited with code $last_exit_code on line $line_number"
  fi
}

# https://medium.com/@dirk.avery/the-bash-trap-trap-ce6083f36700
# keep track of the last executed command
trap 'last_command=$current_command; current_command=$BASH_COMMAND; last_line=$LINENO' DEBUG
trap 'on_exit $?' EXIT


log(){
  local timestamp=$(date +%Y-%m-%d\ %H:%M:%S)
  echo "[deply/db $STAGE_NAME $PERIODICITY $timestamp] $1"
}

load_dotenv(){
  if [ -f .env ]
  then
    log "loading .env file"
    export $(cat .env | sed 's/#.*//g' | xargs)
  else
    log ".env file missing. Aborting"
    exit 1
  fi
}


update_local_neo4j() {
  reset_indices() {
    # RUN THIS ONLY MANUALLY
    # remove indices from automatic steps
    log "defining indices"
    cat sdg/SD-indices.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD
  }

  update_fulltext_biorxiv() {
    # run monthly

    log "updating meca archives"
    aws s3 sync --request-payer requester --exclude "*" --include "*.meca" s3://biorxiv-src-monthly/Current_Content /usb01/shared/biorxiv-src-monthly
    # alternative using docker
    # docker run --rm -it -v ~/.aws:/root/.aws --mount type=bind,source=/raid/lemberge/sd-graph/biorxiv/Current_Content/July_2020,target=/root/Current_Content/July_2020 amazon/aws-cli s3 sync --request-payer requester --exclude "*" --include "*.meca" s3://biorxiv-src-monthly/Current_Content/July_2020 ./Current_Content/July_2020 --dryrun

    log "remove prelim articles obtained from the CrossRef and bioRxiv APIs"
    cat neotools/purge_prelim.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "import full text biorxiv preprints"
    # this is missing the July_2020
    #docker-compose run --rm -v /usb01/shared/biorxiv-src-monthly:/biorxiv-src-monthly flask python -m neotools.rxiv2neo /biorxiv-src-monthly/July_2020 --type meca
    local CURRENT_MONTH=`date +%B`
    local CURRENT_YEAR=`date +%Y`
    docker-compose run --rm -v /usb01/shared/biorxiv-src-monthly:/biorxiv-src-monthly flask python -m neotools.rxiv2neo /biorxiv-src-monthly/"$CURRENT_MONTH"_"$CURRENT_YEAR" --type meca
  }

  import_peer_reviews_from_hypo() {
    # daily
    log "import peer reviews from hypothesis & complete our db with biorxiv prelim api if our meca-fulltext-db missed one"
    docker-compose run --rm flask python -m peerreview.neohypo
  }

  mark_peer_reviews_as_published() {
    # weekly
    log "updates publication status (find out if a preprint has been published in a journal)"
    docker-compose run --rm flask python -m peerreview.published # maybe run only once a week?
  }

  smarttag() {
    # daily
    log "smarttag specified collection of preprints"
    docker-compose run --rm flask python -m sdg.sdneo covid19 --api eebapi

    log "smarttag specified collection of preprints"
    docker-compose run --rm flask python -m sdg.sdneo refereed-preprints --api eebapi
  }

  import_SD() {
    # monthly
    log "import source data public data. Logging to `log/sdg.sdneo-publicsearch.log`"
    docker-compose run --rm flask python -m sdg.sdneo PUBLICSEARCH --api sdapi
  }

  merge_and_precompute_graph() {
    # daily
    log "generate merged graph"
    cat sdg/SD-processing.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD

    log "precompute the graph used by front end"
    cat sdg/SD-precompute.cql | docker-compose run --rm neo4j cypher-shell -a bolt://neo4j:7687 -u neo4j -p $NEO_PASSWORD
  }


  log "starting docker"
  docker-compose build
  docker-compose up -d

  local PERIODICITY=$1
  case $PERIODICITY in
    "monthly")
      log "Running monthly update"
      update_fulltext_biorxiv # monthly
      import_peer_reviews_from_hypo # daily
      mark_peer_reviews_as_published # weekly
      smarttag # daily
      import_SD # monthly
      merge_and_precompute_graph # daily
      ;;
    "weekly")
      log "Running weekly update, it's Monday!"
      import_peer_reviews_from_hypo # daily
      mark_peer_reviews_as_published # weekly
      smarttag # daily
      merge_and_precompute_graph # daily
      ;;
    "daily")
      log "Running daily update"
      import_peer_reviews_from_hypo # daily
      smarttag # daily
      merge_and_precompute_graph # daily
      ;;
  esac

  log "done"
}



publish_on_twitter(){
  log "publishing on twitter"
  docker-compose run --rm flask python -m twitter.update --limit-date 2020-07-01 # --GO_LIVE to go live with Twitter updates
}


dump_local_neo4j(){
  local DUMP_NAME=$1
  log "[dumping neo4j] - start"
  log "  * stopping docker-compose"
  # Make sure you dont have your neo4j running:
  docker-compose down

  log "  * removing older dumps"
  docker run --rm --name neo4j-dump --env-file .env --mount type=bind,source=$PWD/data/neo4j-data,target=/data neo4j:3.5 find /data -type f -name graph.db.dump* -delete

  log "  * dumping to data/neo4j-data/$DUMP_NAME"
  # dump the contents of your database using a temporary container
  docker run --rm --name neo4j-dump --env-file .env --mount type=bind,source=$PWD/data/neo4j-data,target=/data neo4j:3.5 bin/neo4j-admin dump --database=graph.db --to=data/$DUMP_NAME

  log "  * restarting docker-compose"
  docker-compose up -d
  log "[dumping neo4j] - done"
}

deploy_database(){
  local SERVER_ADDRESS="ec2-user@$1"
  local NEO4J_DUMP_LOCAL_PATH=$2
  local NEO4J_DUMP_REMOTE_PATH="/home/ec2-user/sd-graph/graph.dump"

  log "[deploy database] - $SERVER_ADDRESS"

  log "  * scp $NEO4J_DUMP_LOCAL_PATH"
  scp $NEO4J_DUMP_LOCAL_PATH $SERVER_ADDRESS:$NEO4J_DUMP_REMOTE_PATH

  log "  * scp loading neo4j dump on remote"
  ssh $SERVER_ADDRESS "cd /home/ec2-user/sd-graph && ./deploy/__db__/remote"

  local wait_for_docker_in_minutes=5
  log "  * waiting $wait_for_docker_in_minutes minutes to be sure docker is up and running"
  sleep $(( $wait_for_docker_in_minutes * 60 ))
}

cache_warmup(){
  local HOST=$1
  local SERVER_ADDRESS="https://$HOST"
  log "Cache warmup:"
  log "   * $SERVER_ADDRESS/api/v1/automagic/"
  curl $SERVER_ADDRESS/api/v1/automagic/ > /dev/null 2>&1
  log "   * $SERVER_ADDRESS/api/v1/by_hyp/"
  curl $SERVER_ADDRESS/api/v1/by_hyp/ > /dev/null 2>&1
  log "   * $SERVER_ADDRESS/api/v1/by_reviewing_service/"
  curl $SERVER_ADDRESS/api/v1/by_reviewing_service/ > /dev/null 2>&1
  log "   * $SERVER_ADDRESS/api/v1/stats"
  curl $SERVER_ADDRESS/api/v1/stats > /dev/null 2>&1
}

main() {

  # parse arguments
  while [ $# -gt 0 ]; do
    case "$1" in
      --stage_name*|-s*)
        if [[ "$1" != *=* ]]; then shift; fi # Value is next arg if no `=`
        STAGE_NAME="${1#*=}"
        ;;
      --log_file*|-l*)
        if [[ "$1" != *=* ]]; then shift; fi
        LOG_FILE="${1#*=}"
        ;;
      --help|-h)
        echo "--------------------------------------------------------------------------------------"
        echo "deploy db"
        echo "--------------------------------------------------------------------------------------"
        echo ""
        echo "deploy/db --stage_name STAGE_NAME [--log_file 'PATH/TO/LOG/FILE']"
        echo ""
        echo "Options:"
        echo "  --help | -h"
        echo "  --stage_name | -s (staging|production)"
        echo "  --log_file | -l 'quoted/path/to/file.log'"
        echo ""
        echo "example of usage:"
        echo "  deploy/db --stage_name staging --log_file '/home/eeb/logs/deploydb.log'"
        echo ""
        exit 0
        ;;
      *)
        >&2 printf "Error: Invalid argument\n"
        exit 1
        ;;
    esac
    shift
  done

  case $STAGE_NAME in
    "staging")
      REMOTE_HOST="eeb-dev.embo.org"
      ;;
    "production")
      REMOTE_HOST="eeb.embo.org"
      ;;
    *)
      echo "[ERROR] Argument - please specify a valid --stage_name (staging|production)"
      exit 1
      ;;
  esac

  local DAY_OF_THE_MONTH=$(date +%d)
  local DAY_OF_THE_WEEK=$(date +%u) # 1(monday), 2 (tuesday), ... 7(sunday)
  local MONDAY=1
  if [[ $DAY_OF_THE_MONTH -eq 1 ]]; then
    PERIODICITY="monthly"
  elif [[ $DAY_OF_THE_WEEK -eq $MONDAY ]]; then
    PERIODICITY="weekly"
  else
    PERIODICITY="daily"
  fi


  if [ ! -z $LOG_FILE ]; then
    # LOG_FILE is specified, let's redirect stdout and stderr to the $LOG_FILE
    exec >> $LOG_FILE
    exec 2>&1
  fi

  log "############################################################"
  log "##"
  log "## STARTING SD-GRAPH DB DEPLOY"
  log "##"
  local

  load_dotenv
  update_local_neo4j $PERIODICITY
  NEO4J_DUMP_NAME="graph.db.dump.`date +%Y-%m-%d-%H.%M.%S`"
  dump_local_neo4j $NEO4J_DUMP_NAME
  # deploy_database_to_staging data/neo4j-data/$NEO4J_DUMP_NAME
  deploy_database $REMOTE_HOST data/neo4j-data/$NEO4J_DUMP_NAME
  cache_warmup $REMOTE_HOST

  log "##"
  log "## FINISHED SD-GRAPH DB DEPLOY"
  log "##"
  log "############################################################"
  echo "done :)"
}

main $@
