from lxml.etree import Element, XMLParser, parse
from typing import Dict, List
import re
from zipfile import ZipFile
from pathlib import Path
from io import BytesIO
from argparse import ArgumentParser
from .utils import inner_text
from .model import JATS_GRAPH_MODEL
from .queries import SOURCE_BY_UUID, CREATE_FULLTEXT_INDEX
from . import DB

NS = {
    'w': 'http://www.wiley.com/namespaces/wiley',
    'xml': 'http://www.w3.org/XML/1998/namespace'
}

DEBUG_MODE = False


def cleanup_name(name):
    hyphen = re.compile(r'-')
    ns_prefix = re.compile(r'^{\S+}')
    name = hyphen.sub('_', name)
    name = ns_prefix.sub('', name)
    return name


def cleanup_properties(properties):
    clean_prop = {cleanup_name(k): v for k, v in properties.items()}
    return clean_prop


class XMLNode:
    """
    Nodes formed by recursively traversing the xml tree using the graph model.
    The properties of the nodes are generated by using the recipe provided by the graph model.
    Terminal leaf nodes have no children and the innertext is then used as text property.
    The graph model provides the relationships to each subset of children.
    Each subset has an XPath to extrac the respective children from the current element.

    Args:
        element (Element): the xml element to use to creat the node
        graph_model (Dict): the current graph model
        position_idx (int): the position of the element if it is part of a sequence

    Attributes:
        label: the node label
        properties: the properties of the node
        children (Dict): dictionary of childrens, where keys are relationship and value are the subgraph models

    """
    def __init__(self, element: Element, graph_model: Dict, position_idx: int = None):
        # this_element_path_was = graph_model['XPath']
        # this_element_children = graph_model['children']
        # this_element_xpath_to_properties = graph_model['properties']
        self.label = cleanup_name(element.tag).capitalize()
        recipe_for_properties = graph_model.get('properties', None)
        properties = {}
        if recipe_for_properties is not None:
            # the properties are extracted with the recipe consisting of an xpath and a method
            properties = self.find_properties(element, recipe_for_properties)
        if graph_model:  # not terminal
            properties['text'] = element.text or ''
        else:  # terminal leaf node
            properties['text'] = inner_text(element)
        properties['tail'] = element.tail or ''
        if position_idx is not None:
            properties['position_idx'] = position_idx
        # remove hyphens and namespace prefix
        self.properties = cleanup_properties(properties)
        self.children = self.find_children(element, graph_model.get('children', None))

    def find_properties(self, element, recipe: Dict):
        properties = {}
        for property in recipe:
            xpath, funct = recipe[property]
            target_element = element.xpath(xpath)
            if target_element:
                target_value = funct(target_element[0])
                if target_value is not None:
                    properties[property] = target_value
        return properties

    def find_children(self, element, graph_model):
        graph = {}
        if graph_model is not None:
            for relationship in graph_model:
                xp = graph_model[relationship]['XPath']
                sub_model = graph_model[relationship]
                elements = element.xpath(xp)
                add_index = len(elements) > 1
                sub_graph = [XMLNode(e, sub_model, position_idx=i) if add_index else XMLNode(e, sub_model) for i, e in enumerate(elements)]
                graph[relationship] = sub_graph
        return graph

    def to_str(self, indent=0):
        indentation = "    " * indent
        s = ""
        s += indentation + f"({self.label} {self.properties})\n"
        for rel in self.children:
            s += indentation + f"-[{rel}]->\n"
            for c in self.children[rel]:
                s += indentation + c.to_str(indent+1) + "\n"
        return s

    def __str__(self):
        return self.to_str()


def build_neo_graph(xml_node: XMLNode, source: str):
    properties = xml_node.properties # deal with types!
    properties['source'] = source
    node = DB.node(xml_node)

    for rel, children in xml_node.children.items():
        for child in children:
            child_node = build_neo_graph(child, source)
            DB.relationship(node, child_node, rel)
    return node


def add_index():
    DB.multi_statement_query(CREATE_FULLTEXT_INDEX)


class ArchiveLoader:

    def __init__(self, path: Path, glob_pattern='*.meca', check_for_duplicate=False):
        self.path = path
        self.archives = self.path.glob(glob_pattern)
        self.check_for_duplicate = check_for_duplicate

    def load_full_text(self, z: ZipFile, meca_archive, path_full_text: str):
        with z.open(path_full_text) as full_text_xml:
            print(f"parsing {meca_archive}/{path_full_text}")
            xml = parse(full_text_xml).getroot() # root is <article>
            source = meca_archive.name
            xml_node = XMLNode(xml, JATS_GRAPH_MODEL)
            build_neo_graph(xml_node, source)

    def already_loaded(self, meca_archive: Path):
        def tx_funct(tx, q, params):
            results = tx.run(q, params)
            found_one = results.single() is not None
            summary = results.summary()
            notifications = summary.notifications
            if notifications:
                print(f"WARNING: {notifications} when checking for duplicates.")
                print(summary.statement)
                print(summary.parameters)
            return found_one
        found_it = DB.query_with_tx_funct(tx_funct, SOURCE_BY_UUID, {'source': meca_archive.name})
        # results = DB.query(SOURCE_BY_UUID, {'source': meca_archive.name})
        # return results.single() is not None
        return found_it

    def extract_from_manifest(self, z: ZipFile):
        with z.open('manifest.xml') as manifest:
            x_manifest = parse(manifest).getroot()
            ns = {'ns': x_manifest.nsmap[None]}
            article_item = x_manifest.xpath('ns:item[@type="article"]/ns:instance[@media-type="application/xml"]', namespaces=ns)[0]
            path_full_text = article_item.attrib['href']
        return path_full_text

    def find_alternative(self, xml_file_list: List, path_full_text):
        for filename in xml_file_list:
            basename_from_manifest = Path(path_full_text).stem
            existing_basename = Path(filename).stem
            # trying conservative method to find an alternative xml file with only version number as alteration
            if re.match(basename_from_manifest + r'v\d+', existing_basename):
                break
        return filename

    def load_dir(self):
        for meca_archive in self.archives:
            if self.check_for_duplicate and self.already_loaded(meca_archive):
                print(f"WARNING: {meca_archive.name} already loaded. Skipping.", end='\r')
            else:
                with ZipFile(meca_archive) as z:
                    xml_file_list = [f for f in z.namelist() if Path(f).suffix == '.xml']
                    path_full_text = self.extract_from_manifest(z)
                    if path_full_text not in xml_file_list:
                        print(f"WARNING: the file {path_full_text} indicated in the manifest is not in {meca_archive}")
                        path_full_text = self.find_alternative(xml_file_list, path_full_text)
                        print(f"Trying {path_full_text} instead.")
                    self.load_full_text(z, meca_archive, path_full_text)


def self_test():
    xml_str = b'''<?xml version="1.0" encoding="UTF-8"?>
    <!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
    <article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
        <front>
            <article-meta>
                <article-id pub-id-type="doi">10.1101/2020.03.02.972935</article-id>
                <article-version>1.1</article-version>
                <title-group>
                    <article-title>Isolation 'and' "characterization"  $of {SARS-CoV-2} from H&#x00F4;pital Bichat the first \US COVID-19 patient</article-title>
                </title-group>
                <abstract>This is the abstract.</abstract>              
                <contrib-group>
                    <contrib contrib-type="author">
                        <contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-1012-2226</contrib-id>
                        <name><surname>Liu</surname><given-names>Chuang</given-names></name>
                        <xref ref-type="aff" rid="a1">1</xref>
                        <xref ref-type="aff" rid="a3">3</xref>
                        <xref ref-type="author-notes" rid="n2">&#x002A;</xref>
                    </contrib>
                    <contrib contrib-type="author">
                        <name><surname>Yang</surname><given-names>Yang</given-names></name>
                        <xref ref-type="aff" rid="a2">2</xref>
                        <xref ref-type="author-notes" rid="n2">&#x002A;</xref>
                    </contrib>
                </contrib-group>
                <pub-date pub-type="epub"><year>2020</year></pub-date>
            </article-meta>
        </front>
        <body>
            THis and that.
            <fig>
                <label>Figure 3</label>
                <caption>This is nice.</caption>
                <graphic xlink:href="http://this.com/figure/3"/>
            </fig>
        </body>
    </article>
    '''
    tree = parse(BytesIO(xml_str))
    xml_element = tree.getroot()
    graph = XMLNode(xml_element, JATS_GRAPH_MODEL)
    print(graph)
    build_neo_graph(graph, 'test')


if __name__ == '__main__':
    parser = ArgumentParser(description='Parsing xml documents from meca archive and loading into neo4j.')
    parser.add_argument('path', nargs="?", help='Paths to directory containing meca archives.')
    parser.add_argument('--no_duplicate_check', action="store_true", help="Use flag to remove check on whether a paper has already been loaded.")
    args = parser.parse_args()
    path = args.path
    check_for_duplicate = not args.no_duplicate_check
    if path:
        ArchiveLoader(Path(path), check_for_duplicate=check_for_duplicate).load_dir()
        add_index()
    else:
        self_test()
